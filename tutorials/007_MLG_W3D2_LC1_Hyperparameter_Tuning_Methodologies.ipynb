{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEUEZ6cGTmYc"
      },
      "source": [
        "<center><a target=\"_blank\" href=\"http://www.propulsion.academy\"><img src=\"https://drive.google.com/uc?id=1MleNI0rcICpvrGd7SdYuQz7dn8NlAlEc\" width=\"200\" style=\"background:none; border:none; box-shadow:none;\" /></a> </center>\n",
        "\n",
        "_____\n",
        "\n",
        "<center> <h1> Hyperparameter Tuning Methodologies (Live coding) </h1> </center>\n",
        "\n",
        "<p style=\"margin-bottom:1cm;\"></p>\n",
        "\n",
        "_____\n",
        "\n",
        "<center>SIT Academy, 2022</center>\n",
        "\n",
        "\n",
        "\n",
        "# 1. Introduction <a id=\"1\"></a> <br>\n",
        "\n",
        "**Hyperparameter tuning** is choosing a set of optimal hyperparameters for a learning algorithm.\n",
        "\n",
        "**What is a hyperparameter?\n",
        "\n",
        "**A hyperparameter is a parameter whose value is set before the learning process begins.**\n",
        "\n",
        "Some examples of hyperparameters include penalty in logistic regression and loss in stochastic gradient descent.\n",
        "\n",
        "In sklearn, hyperparameters are passed in as arguments to the constructor of the model classes.\n",
        "\n",
        "Hyper-parameters are parameters that are not directly learnt within estimators. In scikit-learn they are passed as arguments to the constructor of the estimator classes. Typical examples include C, kernel and gamma for Support Vector Classifier, alpha for Lasso, etc.\n",
        "\n",
        "It is possible and recommended to search the hyper-parameter space for the best Cross-validation i.e evaluating estimator performance score.\n",
        "\n",
        "Any parameter provided when constructing an estimator may be optimized in this manner. Specifically, to find the names and current values for all parameters for a given estimator, we can use the following method\n",
        "\n",
        "estimator.get_params()\n",
        "\n",
        "A search consists of:\n",
        "\n",
        "* an estimator (regressor or classifier such as sklearn.svm.SVC());\n",
        "* a parameter space;\n",
        "* a method for searching or sampling candidates;\n",
        "* a cross-validation scheme;\n",
        "* a score function.\n",
        "\n",
        "Some models allow for specialized, efficient parameter search strategies, outlined below.\n",
        "\n",
        "Two generic approaches to sampling search candidates are provided in scikit-learn:\n",
        "![](https://developer.qualcomm.com/sites/default/files/attachments/learning_resources_03-05.png)\n",
        "**GridSearchCV** :For given values, GridSearchCV exhaustively considers all parameter combinations. The grid search provided by GridSearchCV exhaustively generates candidates from a grid of parameter values specified with the param_grid parameter.\n",
        "For instance, the following param_grid specifies that it has one grid to be explored that is a linear kernel with alpha values in [0.0002,0.0003,0.0004,0.0005,0.0006,0.0007,0.0009], and 'max_iter' i.e maximum 10000 iterations.\n",
        "\n",
        "param_grid = {'alpha':[0.01,0.001,0.0001,0.0002,0.0003,0.0004,0.0005,0.0006,0.0007,0.0009],'max_iter':[10000]}\n",
        "\n",
        "**RandomizedSearchCV**: It can sample a given number of candidates from a parameter space with a specified distribution.\n",
        "After describing these tools we detail best practice applicable to both approaches.\n",
        "\n",
        "Note that it is common that a small subset of those parameters can have a large impact on the predictive or computation performance of the model while others can be left to their default values. It is recommend to read the docstring of the estimator class to get a finer understanding of their expected behavior.\n",
        "\n",
        "Now lets jump into practice.\n",
        "\n",
        "To perform Hyperparameters Optimization in Python, we will use Credit Card Fraud Detection Dataset. \n",
        "\n",
        "The dataset can be downloaded from [here](https://drive.google.com/file/d/1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bo1JyOjHTmYd"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxGmc9zEfWxd"
      },
      "source": [
        "\n",
        "The dataset can be downloaded from [here](https://drive.google.com/file/d/1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH/view?usp=sharing), add it to your google drive in a folder `MyDrive/Machine Learning/data`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCI50HIynCMz",
        "outputId": "7e43d3e2-c75b-4cba-c506-02533516089c"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsSLm9QknA_2"
      },
      "source": [
        "# data_path=\"/gdrive/MyDrive/Machine Learning/data\"\n",
        "# df = pd.read_csv(f'{data_path}/creditcard.csv',na_values = '#NAME?')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2SskeCqViOGx"
      },
      "source": [
        "For big files we could load the data using below command with replacing `FILEID` and `FILENAME`.<br>\n",
        "`wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=FILEID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=FILEID\" -O FILENAME && rm -rf /tmp/cookies.txt`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x8R7ndZeGJB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7beade6e-e3c0-40e9-b384-48efa4f43c69"
      },
      "source": [
        "link = 'https://drive.google.com/file/d/1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH/view?usp=sharing' #public access link for data\n",
        "file_id = link.split(\"/\")[-2]\n",
        "file_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maWn-6ojh2St",
        "outputId": "0487e81b-ca71-4feb-cbe9-b744f2f1590b"
      },
      "source": [
        "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH\" -O 'creditcard.csv' && rm -rf /tmp/cookies.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-09-17 07:47:01--  https://docs.google.com/uc?export=download&confirm=jFZF&id=1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH\n",
            "Resolving docs.google.com (docs.google.com)... 74.125.202.102, 74.125.202.138, 74.125.202.100, ...\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.202.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-54-docs.googleusercontent.com/docs/securesc/v6d8kfv2b1hcs8hvi4qp5qsd96qtk5ef/h0tr5ug9lu8b0rhd7n2k3ms79ku5c57d/1631864775000/15699573888146190962/16160307378354573665Z/1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH?e=download [following]\n",
            "--2021-09-17 07:47:01--  https://doc-14-54-docs.googleusercontent.com/docs/securesc/v6d8kfv2b1hcs8hvi4qp5qsd96qtk5ef/h0tr5ug9lu8b0rhd7n2k3ms79ku5c57d/1631864775000/15699573888146190962/16160307378354573665Z/1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH?e=download\n",
            "Resolving doc-14-54-docs.googleusercontent.com (doc-14-54-docs.googleusercontent.com)... 142.251.6.132, 2607:f8b0:4001:c5a::84\n",
            "Connecting to doc-14-54-docs.googleusercontent.com (doc-14-54-docs.googleusercontent.com)|142.251.6.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://docs.google.com/nonceSigner?nonce=qde4gkbm6vvgq&continue=https://doc-14-54-docs.googleusercontent.com/docs/securesc/v6d8kfv2b1hcs8hvi4qp5qsd96qtk5ef/h0tr5ug9lu8b0rhd7n2k3ms79ku5c57d/1631864775000/15699573888146190962/16160307378354573665Z/1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH?e%3Ddownload&hash=fbt123es4vqh82v4snlrqghjl13alkdt [following]\n",
            "--2021-09-17 07:47:01--  https://docs.google.com/nonceSigner?nonce=qde4gkbm6vvgq&continue=https://doc-14-54-docs.googleusercontent.com/docs/securesc/v6d8kfv2b1hcs8hvi4qp5qsd96qtk5ef/h0tr5ug9lu8b0rhd7n2k3ms79ku5c57d/1631864775000/15699573888146190962/16160307378354573665Z/1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH?e%3Ddownload&hash=fbt123es4vqh82v4snlrqghjl13alkdt\n",
            "Connecting to docs.google.com (docs.google.com)|74.125.202.102|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://doc-14-54-docs.googleusercontent.com/docs/securesc/v6d8kfv2b1hcs8hvi4qp5qsd96qtk5ef/h0tr5ug9lu8b0rhd7n2k3ms79ku5c57d/1631864775000/15699573888146190962/16160307378354573665Z/1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH?e=download&nonce=qde4gkbm6vvgq&user=16160307378354573665Z&hash=15kim8581forhljj0gob024qjkinhblk [following]\n",
            "--2021-09-17 07:47:01--  https://doc-14-54-docs.googleusercontent.com/docs/securesc/v6d8kfv2b1hcs8hvi4qp5qsd96qtk5ef/h0tr5ug9lu8b0rhd7n2k3ms79ku5c57d/1631864775000/15699573888146190962/16160307378354573665Z/1sEfpj80zNodR8GPQCT_qa8XaQkCbA8RH?e=download&nonce=qde4gkbm6vvgq&user=16160307378354573665Z&hash=15kim8581forhljj0gob024qjkinhblk\n",
            "Connecting to doc-14-54-docs.googleusercontent.com (doc-14-54-docs.googleusercontent.com)|142.251.6.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘creditcard.csv’\n",
            "\n",
            "creditcard.csv          [       <=>          ] 143.84M   110MB/s    in 1.3s    \n",
            "\n",
            "2021-09-17 07:47:03 (110 MB/s) - ‘creditcard.csv’ saved [150828752]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVuJ9bMnh6oi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2ddad94-0f4d-4ef3-b000-d7e81a9a33e0"
      },
      "source": [
        "df = pd.read_csv('creditcard.csv',na_values = '#NAME?')\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(284807, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWaUfiNBMaSZ"
      },
      "source": [
        "df_0 = df[df.Class == 0].sample(n=8000, random_state=999) # select randomly 8000 non fraudulent transaction rows\n",
        "df_1 = df[df.Class == 1].sample(n=80, random_state=999) # select randomly 80 non fraudulent transaction rows\n",
        "df = pd.concat([df_0, df_1], ignore_index=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UFEKxTi-TmYd"
      },
      "source": [
        "X = df.drop(columns='Class')\n",
        "#X.columns = ['transaction_rate', 'amount', 'days_since_last_transaction', 'hour']\n",
        "Y = df['Class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "Uiz1KlKzoGBU",
        "outputId": "63459e25-675a-40e6-c771-856b0e4fc90b"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>85563.0</td>\n",
              "      <td>-2.101793</td>\n",
              "      <td>-1.319715</td>\n",
              "      <td>1.666445</td>\n",
              "      <td>-2.277249</td>\n",
              "      <td>-0.756431</td>\n",
              "      <td>-0.463003</td>\n",
              "      <td>-1.247058</td>\n",
              "      <td>0.681235</td>\n",
              "      <td>-2.461398</td>\n",
              "      <td>0.874610</td>\n",
              "      <td>1.089353</td>\n",
              "      <td>-0.181977</td>\n",
              "      <td>0.582483</td>\n",
              "      <td>-0.162549</td>\n",
              "      <td>-0.148541</td>\n",
              "      <td>0.043328</td>\n",
              "      <td>0.337144</td>\n",
              "      <td>0.484291</td>\n",
              "      <td>-1.028459</td>\n",
              "      <td>-0.138556</td>\n",
              "      <td>0.114293</td>\n",
              "      <td>0.414879</td>\n",
              "      <td>-0.070529</td>\n",
              "      <td>0.008534</td>\n",
              "      <td>0.373403</td>\n",
              "      <td>-0.170413</td>\n",
              "      <td>0.075017</td>\n",
              "      <td>0.027026</td>\n",
              "      <td>52.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>41688.0</td>\n",
              "      <td>0.586683</td>\n",
              "      <td>-0.922169</td>\n",
              "      <td>0.533519</td>\n",
              "      <td>1.402979</td>\n",
              "      <td>-0.580172</td>\n",
              "      <td>0.838403</td>\n",
              "      <td>-0.128986</td>\n",
              "      <td>0.227051</td>\n",
              "      <td>0.513178</td>\n",
              "      <td>-0.249108</td>\n",
              "      <td>0.760067</td>\n",
              "      <td>1.536614</td>\n",
              "      <td>0.471439</td>\n",
              "      <td>-0.214581</td>\n",
              "      <td>-1.018911</td>\n",
              "      <td>-0.391637</td>\n",
              "      <td>-0.073870</td>\n",
              "      <td>-0.147979</td>\n",
              "      <td>-0.017214</td>\n",
              "      <td>0.418535</td>\n",
              "      <td>0.183667</td>\n",
              "      <td>0.252728</td>\n",
              "      <td>-0.380845</td>\n",
              "      <td>-0.239640</td>\n",
              "      <td>0.538160</td>\n",
              "      <td>-0.274996</td>\n",
              "      <td>0.023832</td>\n",
              "      <td>0.058588</td>\n",
              "      <td>277.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>44881.0</td>\n",
              "      <td>-0.718815</td>\n",
              "      <td>1.150030</td>\n",
              "      <td>0.987635</td>\n",
              "      <td>0.553702</td>\n",
              "      <td>0.080471</td>\n",
              "      <td>0.728115</td>\n",
              "      <td>0.688676</td>\n",
              "      <td>-0.016909</td>\n",
              "      <td>-0.338821</td>\n",
              "      <td>0.466067</td>\n",
              "      <td>0.151933</td>\n",
              "      <td>0.128944</td>\n",
              "      <td>0.345608</td>\n",
              "      <td>0.023787</td>\n",
              "      <td>0.652402</td>\n",
              "      <td>0.452300</td>\n",
              "      <td>-1.084521</td>\n",
              "      <td>1.264135</td>\n",
              "      <td>0.933067</td>\n",
              "      <td>-0.030013</td>\n",
              "      <td>0.233130</td>\n",
              "      <td>0.883804</td>\n",
              "      <td>-0.351194</td>\n",
              "      <td>-0.801294</td>\n",
              "      <td>-0.254959</td>\n",
              "      <td>-0.263018</td>\n",
              "      <td>-0.608508</td>\n",
              "      <td>-0.397528</td>\n",
              "      <td>77.30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>119711.0</td>\n",
              "      <td>1.707167</td>\n",
              "      <td>-1.372546</td>\n",
              "      <td>-2.076366</td>\n",
              "      <td>-1.731858</td>\n",
              "      <td>1.453493</td>\n",
              "      <td>3.507479</td>\n",
              "      <td>-0.962745</td>\n",
              "      <td>0.915780</td>\n",
              "      <td>1.304930</td>\n",
              "      <td>-0.461834</td>\n",
              "      <td>0.196558</td>\n",
              "      <td>0.549854</td>\n",
              "      <td>0.073093</td>\n",
              "      <td>0.220704</td>\n",
              "      <td>1.594200</td>\n",
              "      <td>0.235073</td>\n",
              "      <td>-0.581078</td>\n",
              "      <td>-0.400018</td>\n",
              "      <td>0.083800</td>\n",
              "      <td>0.256385</td>\n",
              "      <td>-0.074749</td>\n",
              "      <td>-0.600467</td>\n",
              "      <td>0.301127</td>\n",
              "      <td>0.722943</td>\n",
              "      <td>-0.666974</td>\n",
              "      <td>0.336647</td>\n",
              "      <td>-0.051282</td>\n",
              "      <td>-0.022926</td>\n",
              "      <td>175.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33924.0</td>\n",
              "      <td>-0.884826</td>\n",
              "      <td>0.745981</td>\n",
              "      <td>1.967062</td>\n",
              "      <td>-0.356323</td>\n",
              "      <td>0.139664</td>\n",
              "      <td>0.909589</td>\n",
              "      <td>0.135413</td>\n",
              "      <td>0.195846</td>\n",
              "      <td>0.630394</td>\n",
              "      <td>0.254632</td>\n",
              "      <td>-0.256223</td>\n",
              "      <td>0.182050</td>\n",
              "      <td>-0.100807</td>\n",
              "      <td>-0.693385</td>\n",
              "      <td>-0.519890</td>\n",
              "      <td>0.491002</td>\n",
              "      <td>-0.969612</td>\n",
              "      <td>0.830814</td>\n",
              "      <td>0.903568</td>\n",
              "      <td>0.336394</td>\n",
              "      <td>-0.163673</td>\n",
              "      <td>-0.041402</td>\n",
              "      <td>-0.368921</td>\n",
              "      <td>-0.933949</td>\n",
              "      <td>0.081282</td>\n",
              "      <td>0.339777</td>\n",
              "      <td>0.135426</td>\n",
              "      <td>0.000846</td>\n",
              "      <td>11.50</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2        V3  ...       V26       V27       V28  Amount\n",
              "0   85563.0 -2.101793 -1.319715  1.666445  ... -0.170413  0.075017  0.027026   52.00\n",
              "1   41688.0  0.586683 -0.922169  0.533519  ... -0.274996  0.023832  0.058588  277.22\n",
              "2   44881.0 -0.718815  1.150030  0.987635  ... -0.263018 -0.608508 -0.397528   77.30\n",
              "3  119711.0  1.707167 -1.372546 -2.076366  ...  0.336647 -0.051282 -0.022926  175.00\n",
              "4   33924.0 -0.884826  0.745981  1.967062  ...  0.339777  0.135426  0.000846   11.50\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVU_x0jPoIZo",
        "outputId": "3eef45d1-6e52-4d1f-faa4-dae1340eed04"
      },
      "source": [
        "Y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "lCtCYgEKTmYe"
      },
      "source": [
        "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size=0.3, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSCA7LBFoXzg",
        "outputId": "14076ba1-650a-4df4-d7b9-62023edafaaf"
      },
      "source": [
        "X_Train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5656, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2r4jU6UH_vF",
        "outputId": "b5c7ad49-3ab2-44b6-c39e-c3d621271dea"
      },
      "source": [
        "Y_Train.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    5597\n",
              "1      59\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DSSVuBOTmYe"
      },
      "source": [
        "# 2. Manual Search <a id=\"2\"></a> <br>\n",
        "We will use a Random Forest Classifier as our model to optimize.Random Forest models are formed by a large number of uncorrelated decision trees, which joint together constitute an ensemble. In Random Forest, each decision tree makes its own prediction and the overall model output is selected to be the prediction which appeared most frequently.\n",
        "\n",
        "We can now start by calculating our base model accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rudIUokQTmYe",
        "outputId": "d1961b08-b57b-4102-8392-8eebabb0142a"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(random_state=42).fit(X_Train, Y_Train)\n",
        "predictionforest = model.predict(X_Test)\n",
        "\n",
        "print(confusion_matrix(Y_Test, predictionforest))\n",
        "print(classification_report(Y_Test, predictionforest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2401    2]\n",
            " [   2   19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2403\n",
            "           1       0.90      0.90      0.90        21\n",
            "\n",
            "    accuracy                           1.00      2424\n",
            "   macro avg       0.95      0.95      0.95      2424\n",
            "weighted avg       1.00      1.00      1.00      2424\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O1Vqg38omz_",
        "outputId": "2f7533fa-2532-447a-a3f9-ffe6f1fab021"
      },
      "source": [
        "model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PL-3w6B8TmYf"
      },
      "source": [
        "When using Manual Search, we choose some model hyperparameters based on our judgment/experience. We then train the model, evaluate its accuracy and start the process again. This loop is repeated until a satisfactory accuracy is scored.\n",
        "\n",
        "The main parameters used by a Random Forest Classifier are:\n",
        "\n",
        "* criterion = the function used to evaluate the quality of a split.\n",
        "* max_depth = maximum number of levels allowed in each tree.\n",
        "* max_features = maximum number of features considered when splitting a node.\n",
        "* min_samples_leaf = minimum number of samples which can be stored in a tree leaf.\n",
        "* min_samples_split = minimum number of samples necessary in a node to cause node splitting.\n",
        "* n_estimators = number of trees in the ensemble."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja0QaBmrTmYf",
        "outputId": "8f54ba51-ca4d-4bc9-b782-5815581a9500"
      },
      "source": [
        "model = RandomForestClassifier(n_estimators=50, random_state=42).fit(X_Train,Y_Train)\n",
        "predictionforest = model.predict(X_Test)\n",
        "print(confusion_matrix(Y_Test,predictionforest))\n",
        "print(classification_report(Y_Test,predictionforest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2401    2]\n",
            " [   2   19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2403\n",
            "           1       0.90      0.90      0.90        21\n",
            "\n",
            "    accuracy                           1.00      2424\n",
            "   macro avg       0.95      0.95      0.95      2424\n",
            "weighted avg       1.00      1.00      1.00      2424\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuPfL9wtTmYg"
      },
      "source": [
        "# 3. Random Search <a id=\"3\"></a> <br>\n",
        "\n",
        "In Random Search, we create a grid of hyperparameters and train/test our model on just some random combination of these hyperparameters. In this example, we additionally perform Cross-Validation on the training set.\n",
        "\n",
        "When performing Machine Learning tasks, we generally divide our dataset in training and test sets. This is done so that to test our model after having trained it (in this way we can check it’s performances when working with unseen data). When using Cross-Validation, we divide our training set into N other partitions to make sure our model is not overfitting our data.\n",
        "\n",
        "One of the most common used Cross-Validation methods is K-Fold Validation. In K-Fold, we divide our training set into N partitions and then iteratively train our model using N-1 partitions and test it with the left-over partition (at each iteration we change the left-over partition). Once having trained N times the model we then average the training results obtained in each iteration to obtain our overall training performance results.\n",
        "\n",
        "Using Cross-Validation when implementing Hyperparameters optimization can be really important. In this way, we might avoid using some Hyperparameters which works really good on the training data but not so good with the test data.\n",
        "We can now start implementing Random Search by first defying a grid of hyperparameters which will be randomly sampled when calling RandomizedSearchCV()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeKTBQszTmYg",
        "outputId": "a0ff6828-085d-4044-dab9-8d6a18cf7503"
      },
      "source": [
        "import numpy as np \n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "random_search = {'criterion': ['entropy', 'gini'],\n",
        "                 'max_depth': [10, 20, None],\n",
        "                 'max_features': ['sqrt', 'log2'],\n",
        "                 'n_estimators': [50, 100, 200]}\n",
        "\n",
        "               # 2 x 3 x 2 x 3 = 36 => randomly selects 10 combinations (models) from 36 possible model hyperparameter configs\n",
        "               # 1. RandomForestClassifier(criterion='gini', max_depth=10, max_features='sqrt', n_estimators=50)\n",
        "               # 2. RandomForestClassifier(criterion='entropy', max_depth=20, max_features='log2', n_estimators=200)\n",
        "               # ... total of n_iter models\n",
        "\n",
        "\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "random_search_obj = RandomizedSearchCV(estimator=clf, \n",
        "                           param_distributions=random_search, \n",
        "                           n_iter=10, # total number of models it will try out by random selections\n",
        "                           scoring='f1',\n",
        "                           cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
        "\n",
        "random_search_obj.fit(X_Train, Y_Train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   30.4s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3, error_score=nan,\n",
              "                   estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                    ccp_alpha=0.0,\n",
              "                                                    class_weight=None,\n",
              "                                                    criterion='gini',\n",
              "                                                    max_depth=None,\n",
              "                                                    max_features='auto',\n",
              "                                                    max_leaf_nodes=None,\n",
              "                                                    max_samples=None,\n",
              "                                                    min_impurity_decrease=0.0,\n",
              "                                                    min_impurity_split=None,\n",
              "                                                    min_samples_leaf=1,\n",
              "                                                    min_samples_split=2,\n",
              "                                                    min_weight_fraction_leaf=0.0,\n",
              "                                                    n_estimators=100,\n",
              "                                                    n_jobs=None,\n",
              "                                                    oob_score=False,\n",
              "                                                    random_state=42, verbose=0,\n",
              "                                                    warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=-1,\n",
              "                   param_distributions={'criterion': ['entropy', 'gini'],\n",
              "                                        'max_depth': [10, 20, None],\n",
              "                                        'max_features': ['sqrt', 'log2'],\n",
              "                                        'n_estimators': [50, 100, 200]},\n",
              "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
              "                   return_train_score=False, scoring='f1', verbose=1)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y57lhJjJTmYh"
      },
      "source": [
        "Once trained our model, we can then visualize how changing some of its Hyperparameters can affect the overall model accuracy. In this case, we observe how changing the number of estimators and the criterion can affect our Random Forest accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB8m2y0WTmYh"
      },
      "source": [
        "We can now evaluate how our model performed using Random Search. In this case, using Random Search leads to a consistent increase in accuracy compared to our base model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItPr5n2YpZDb",
        "outputId": "5b62271d-7ed5-45b1-c1d6-fc7da8f608b2"
      },
      "source": [
        "# best model\n",
        "best_model = random_search_obj.best_estimator_\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=20, max_features='sqrt',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
              "                       n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYSdWOSvpi0g",
        "outputId": "ea851ed3-6858-4b3b-b78f-f9239815240c"
      },
      "source": [
        "# best params\n",
        "random_search_obj.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_depth': 20,\n",
              " 'max_features': 'sqrt',\n",
              " 'n_estimators': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "tBlmnrfzpopK",
        "outputId": "d3cfa1f3-73e0-4ff1-e038-19a447530e62"
      },
      "source": [
        "# detailed history of all models tried and their performance in cross validation\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "cv_result_df = pd.DataFrame({\n",
        "    'Model Rank': random_search_obj.cv_results_['rank_test_score'],\n",
        "    'Model Hyperparams': random_search_obj.cv_results_['params'],\n",
        "    'Avg CV F1-Score': random_search_obj.cv_results_['mean_test_score'],\n",
        "    'Std Dev CV F1-Score': random_search_obj.cv_results_['std_test_score'],\n",
        "    'CV Fold 1 F1-Score': random_search_obj.cv_results_['split0_test_score'],\n",
        "    'CV Fold 2 F1-Score': random_search_obj.cv_results_['split1_test_score'],\n",
        "    'CV Fold 3 F1-Score': random_search_obj.cv_results_['split2_test_score']\n",
        "})\n",
        "\n",
        "\n",
        "cv_result_df.sort_values(by=['Model Rank'], ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model Rank</th>\n",
              "      <th>Model Hyperparams</th>\n",
              "      <th>Avg CV F1-Score</th>\n",
              "      <th>Std Dev CV F1-Score</th>\n",
              "      <th>CV Fold 1 F1-Score</th>\n",
              "      <th>CV Fold 2 F1-Score</th>\n",
              "      <th>CV Fold 3 F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>{'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'gini'}</td>\n",
              "      <td>0.851852</td>\n",
              "      <td>0.094426</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.944444</td>\n",
              "      <td>0.722222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>{'n_estimators': 50, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini'}</td>\n",
              "      <td>0.841799</td>\n",
              "      <td>0.085187</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.722222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>{'n_estimators': 100, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'gini'}</td>\n",
              "      <td>0.841799</td>\n",
              "      <td>0.085187</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.722222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>{'n_estimators': 200, 'max_features': 'log2', 'max_depth': None, 'criterion': 'gini'}</td>\n",
              "      <td>0.829630</td>\n",
              "      <td>0.102290</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.685714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>{'n_estimators': 50, 'max_features': 'log2', 'max_depth': 10, 'criterion': 'gini'}</td>\n",
              "      <td>0.816744</td>\n",
              "      <td>0.120433</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.914286</td>\n",
              "      <td>0.647059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6</td>\n",
              "      <td>{'n_estimators': 100, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy'}</td>\n",
              "      <td>0.815126</td>\n",
              "      <td>0.077930</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>6</td>\n",
              "      <td>{'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 20, 'criterion': 'entropy'}</td>\n",
              "      <td>0.815126</td>\n",
              "      <td>0.077930</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.882353</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>{'n_estimators': 50, 'max_features': 'sqrt', 'max_depth': None, 'criterion': 'entropy'}</td>\n",
              "      <td>0.814419</td>\n",
              "      <td>0.078499</td>\n",
              "      <td>0.888889</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.705882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>{'n_estimators': 200, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy'}</td>\n",
              "      <td>0.810967</td>\n",
              "      <td>0.059286</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10</td>\n",
              "      <td>{'n_estimators': 100, 'max_features': 'log2', 'max_depth': None, 'criterion': 'entropy'}</td>\n",
              "      <td>0.798972</td>\n",
              "      <td>0.053875</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.727273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Model Rank  ... CV Fold 3 F1-Score\n",
              "2           1  ...           0.722222\n",
              "3           2  ...           0.722222\n",
              "5           2  ...           0.722222\n",
              "0           4  ...           0.685714\n",
              "6           5  ...           0.647059\n",
              "1           6  ...           0.705882\n",
              "8           6  ...           0.705882\n",
              "7           8  ...           0.705882\n",
              "9           9  ...           0.727273\n",
              "4          10  ...           0.727273\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLxrGD5bTmYi",
        "outputId": "c7986c56-d6cb-4c9e-8ec4-9724c4da656c"
      },
      "source": [
        "predictionforest = best_model.predict(X_Test)\n",
        "print(confusion_matrix(Y_Test,predictionforest))\n",
        "print(classification_report(Y_Test,predictionforest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2401    2]\n",
            " [   2   19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2403\n",
            "           1       0.90      0.90      0.90        21\n",
            "\n",
            "    accuracy                           1.00      2424\n",
            "   macro avg       0.95      0.95      0.95      2424\n",
            "weighted avg       1.00      1.00      1.00      2424\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7fGJdtRTmYi"
      },
      "source": [
        "# 4. Grid Search <a id=\"4\"></a> <br>\n",
        "In Grid Search, we set up a grid of hyperparameters and train/test our model on each of the possible combinations.\n",
        "In order to choose the parameters to use in Grid Search, we can now look at which parameters worked best with Random Search and form a grid based on them to see if we can find a better combination.\n",
        "\n",
        "Grid Search can be implemented in Python using scikit-learn GridSearchCV() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yVTY0JtTmYi",
        "outputId": "8dec900f-fcfc-4471-fed2-4e51bb3b0efa"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_search = {'criterion': ['entropy', 'gini'],\n",
        "                 'max_depth': [10, 20, None],\n",
        "                 'max_features': ['sqrt', 'log2'],\n",
        "                 'n_estimators': [50, 100, 200]}\n",
        "               # 2 x 3 x 2 x 3 = 36 => Total of 36 models from 36 possible model hyperparameter configs\n",
        "               # 1. RandomForestClassifier(criterion='entropy', max_depth=10, max_features='sqrt', n_estimators=50)\n",
        "               # 2. RandomForestClassifier(criterion='entropy', max_depth=20, max_features='sqrt', n_estimators=50)\n",
        "               # 3. RandomForestClassifier(criterion='entropy', max_depth=None, max_features='sqrt', n_estimators=50)\n",
        "               # 4. RandomForestClassifier(criterion='entropy', max_depth=10, max_features='log2', n_estimators=50)\n",
        "               # ... total of 36 models\n",
        "\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "grid_search_obj = GridSearchCV(estimator=clf, \n",
        "                               param_grid=grid_search,\n",
        "                               scoring='f1', cv=3, verbose=5, n_jobs=-1)\n",
        "\n",
        "grid_search_obj.fit(X_Train,Y_Train)\n",
        "\n",
        "predictionforest = grid_search_obj.best_estimator_.predict(X_Test)\n",
        "print(confusion_matrix(Y_Test,predictionforest))\n",
        "print(classification_report(Y_Test,predictionforest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 36 candidates, totalling 108 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:   13.2s\n",
            "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed:  1.0min\n",
            "[Parallel(n_jobs=-1)]: Done 108 out of 108 | elapsed:  1.6min finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2401    2]\n",
            " [   2   19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2403\n",
            "           1       0.90      0.90      0.90        21\n",
            "\n",
            "    accuracy                           1.00      2424\n",
            "   macro avg       0.95      0.95      0.95      2424\n",
            "weighted avg       1.00      1.00      1.00      2424\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq8NCQ9_LS8t",
        "outputId": "bf7c5c14-7fbc-49bc-d9eb-7c736f37d1f1"
      },
      "source": [
        "grid_search_obj.best_params_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini',\n",
              " 'max_depth': 20,\n",
              " 'max_features': 'sqrt',\n",
              " 'n_estimators': 200}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQGHzW5ATmYj"
      },
      "source": [
        "Grid Search is slower compared to Random Search but it can be overall more effective because it can go through the whole search space. Instead, Random Search can be faster fast but might miss some important points in the search space.\n",
        "# 5. Automated Hyperparameter Tuning <a id=\"5\"></a> <br>\n",
        "\n",
        "![](https://better.future-processing.com/directus/storage/uploads/2399317284eda5016daac68812d5d3c3.png)\n",
        "\n",
        "As we have seen above tuning machine learning hyperparameters is indeed a tedious but crucial task, as the performance of an algorithm can be highly dependent on the choice of hyperparameters. Manual tuning takes time away from important steps of the machine learning pipeline like feature engineering and interpreting results. Grid and random search are hands-off, but require long run times because they waste time evaluating unpromising areas of the search space. Increasingly, hyperparameter tuning is done by automated methods that aim to find optimal hyperparameters in less time using an informed search with no manual effort necessary beyond the initial set-up.\n",
        "\n",
        "When using Automated Hyperparameter Tuning, the model hyperparameters to use are identified using techniques such as: Bayesian Optimization, Gradient Descent and Evolutionary Algorithms.\n",
        "\n",
        "## Bayesian Optimization using HyperOpt <a id=\"51\"></a> <br>\n",
        "\n",
        "![](https://i.imgur.com/BWbgCSx.jpg)\n",
        "Bayesian optimization, a model-based method for finding the minimum of a function,while the final aim is to find the input value to a function which can give us the lowest possible output value has resulted in achieving better performance while requiring fewer iterations than random search.  Bayesian Optimization can, therefore, lead to better performance in the testing phase and reduced optimization time.\n",
        "\n",
        "Bayesian Optimization can be performed in Python using the Hyperopt library.  \n",
        "\n",
        "![](https://camo.githubusercontent.com/b92ead141ef3726da38eef053864aa1173012789/68747470733a2f2f692e706f7374696d672e63632f54506d66665772702f68797065726f70742d6e65772e706e67)\n",
        "\n",
        "In Hyperopt, Bayesian Optimization can be implemented giving 3 three main parameters to the function fmin().\n",
        "\n",
        "* **Objective Function** = defines the loss function to minimize.\n",
        "* **Domain Space** = defines the range of input values to test (in Bayesian Optimization this space creates a probability distribution for each of the used Hyperparameters).\n",
        "* **Optimization Algorithm** = defines the search algorithm to use to select the best input values to use in each new iteration.\n",
        "\n",
        "Additionally, can also be defined in **fmin()** the maximum number of evaluations to perform.\n",
        "\n",
        "Bayesian Optimization can reduce the number of search iterations by choosing the input values bearing in mind the past outcomes. In this way, we can concentrate our search from the beginning on values which are closer to our desired output.\n",
        "We can now run our Bayesian Optimizer using the fmin() function. A Trials() object is first created to make possible to visualize later what was going on while the **fmin()** function was running (eg. how the loss function was changing and how to used Hyperparameters were changing).\n",
        "\n",
        "\n",
        "Hyperopt is one of several automated hyperparameter tuning libraries using Bayesian optimization. These libraries differ in the algorithm used to both construct the surrogate (probability model) of the objective function and choose the next hyperparameters to evaluate in the objective function. Hyperopt uses the Tree Parzen Estimator (TPE). Other Python libraries include Spearmint, which uses a Gaussian process for the surrogate, and SMAC, which uses a random forest regression.\n",
        "\n",
        "Hyperopt has a simple syntax for structuring an optimization problem which extends beyond hyperparameter tuning to any problem that involves minimizing a function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9gGFXx5TmYj",
        "outputId": "7d8edfe0-3e1c-40bb-9c9c-7ca2627e2eec"
      },
      "source": [
        "!pip install hyperopt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.7/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.19.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt) (2.6.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.15.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from hyperopt) (1.4.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt) (3.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt) (4.62.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2topPTTTmYj",
        "outputId": "eeb2bd67-af30-455d-c8d8-a6c0f2ee7150"
      },
      "source": [
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
        "\n",
        "space = {\n",
        "    'criterion': hp.choice('criterion', ['entropy', 'gini']),\n",
        "    'max_depth':  hp.choice('max_depth', [10, 20, None]),\n",
        "    'max_features': hp.choice('max_features', ['sqrt','log2']),\n",
        "    'n_estimators' : hp.choice('n_estimators', [50, 100, 200])   \n",
        "}\n",
        "\n",
        "def objective(space):\n",
        "    model = RandomForestClassifier(criterion = space['criterion'], \n",
        "                                   max_depth = space['max_depth'],\n",
        "                                   max_features = space['max_features'],\n",
        "                                   n_estimators = space['n_estimators'], \n",
        "                                   random_state=42\n",
        "                                 )\n",
        "    \n",
        "    f1 = cross_val_score(model, X_Train, Y_Train, cv=3, scoring='f1').mean()\n",
        "\n",
        "    # We aim to maximize accuracy, therefore we return it as a negative value\n",
        "    return {'loss': -f1, 'status': STATUS_OK }\n",
        "    \n",
        "trials = Trials()\n",
        "\n",
        "best = fmin(fn=objective,\n",
        "            space=space,\n",
        "            algo=tpe.suggest,\n",
        "            max_evals=20,\n",
        "            trials=trials)\n",
        "best"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 20/20 [01:12<00:00,  3.63s/it, best loss: -0.851851851851852]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 1, 'max_depth': 2, 'max_features': 0, 'n_estimators': 2}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlUWI1ipTmYk"
      },
      "source": [
        "We can now retrieve the set of **best** parameters identified and test our model using the **best** dictionary created during training. Some of the parameters have been stored in the **best** dictionary numerically using indices, therefore, we need first to convert them back as strings before input them in our Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGp65iz_TmYk",
        "outputId": "4751794d-34f9-4fd4-e016-5334bcdff51c"
      },
      "source": [
        "crit = {0: 'entropy', 1: 'gini'}\n",
        "feat = {0: 'sqrt', 1: 'log2'}\n",
        "depth = {0: 10, 1: 20, 2: None}\n",
        "est = {0: 50, 1: 100, 2: 200}\n",
        "\n",
        "trainedforest = RandomForestClassifier(criterion = crit[best['criterion']], \n",
        "                                       max_depth = depth[best['max_depth']], \n",
        "                                       max_features = feat[best['max_features']],  \n",
        "                                       n_estimators = est[best['n_estimators']],\n",
        "                                       random_state=42\n",
        "                                      ).fit(X_Train,Y_Train)\n",
        "                                      \n",
        "predictionforest = trainedforest.predict(X_Test)\n",
        "print(confusion_matrix(Y_Test,predictionforest))\n",
        "print(classification_report(Y_Test,predictionforest))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2401    2]\n",
            " [   2   19]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      2403\n",
            "           1       0.90      0.90      0.90        21\n",
            "\n",
            "    accuracy                           1.00      2424\n",
            "   macro avg       0.95      0.95      0.95      2424\n",
            "weighted avg       1.00      1.00      1.00      2424\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "d4a7247b-6654-483b-b8d5-a754c7834efe",
        "_uuid": "78e8638406e22164d84aec94c2742c92da1f19ce",
        "id": "PFMGXiphTmYq"
      },
      "source": [
        "\n",
        "# Conclusion <a id=\"9\"></a> <br>\n",
        "\n",
        "**Now you have a fair understanding of how to do Hyperparameter Tuning with open source libraries as mentioned above.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "I3Yg7xv4YdVu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}